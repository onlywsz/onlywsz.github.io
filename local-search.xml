<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>指标管理平台</title>
    <link href="/2023/10/09/%E6%8C%87%E6%A0%87%E5%B9%B3%E5%8F%B0/"/>
    <url>/2023/10/09/%E6%8C%87%E6%A0%87%E5%B9%B3%E5%8F%B0/</url>
    
    <content type="html"><![CDATA[<h1 id="指标平台概念"><a href="#指标平台概念" class="headerlink" title="指标平台概念"></a>指标平台概念</h1><p>指标平台是通过对指标的统一管理来解决指标数据来源不清晰、指标名称不规范、指标口径不统一等问题，实现指标从定义-配置-应用的整体流程规范化。</p><h1 id="指标建设现状"><a href="#指标建设现状" class="headerlink" title="指标建设现状"></a>指标建设现状</h1><ul><li><p>指标口径不统一</p></li><li><p>指标流程不统一</p></li><li><p>指标管理不统一</p></li><li><p>指标服务不统一</p></li></ul><p><img src="https://cdn.jsdelivr.net/gh/onlywsz/onlywsz.github.io/img/202310101610893.png" alt="指标建设的现状"></p><h1 id="指标平台建设框架"><a href="#指标平台建设框架" class="headerlink" title="指标平台建设框架"></a>指标平台建设框架</h1><p><strong>基本概念</strong></p><ul><li><p>业务板块：根据业务的属性划分出的相对独立的业务板块，业务板块是一种大的划分，各业务板块中的业务重叠度极低，数据独立建设，比如地产板块、金融板块、医疗板块等。</p></li><li><p>原子指标：原子指标是针对某一业务事件行为的度量，是一种不可拆分的指标，具有明确业务含义，比如支付金额。原子指标有确定的字段名称、数据类型、算法说明、所属数据域和业务过程。原子指标名称一般采用“动作+度量”方式命名，比如支付金额、注册用户数。</p></li><li><p>派生指标：派生指标可以理解为对原子指标业务统计范围的圈定，比如最近1天北京买家支付金额（“最近1天”是时间周期，“北京”是修饰词，修饰词“买家”是维度）。派生指标&#x3D;1个原子指标+多个修饰词+时间修饰词。</p><p><img src="https://cdn.jsdelivr.net/gh/onlywsz/onlywsz.github.io/img/202310101519735.jpg" alt="派生指标"></p></li><li><p>衍生指标：复合指标是在事务性指标和存量型指标的基础上复合成的。例如，浏览 UV- 下单买家数转化率，销售额-库存。</p></li><li><p>维度：维度是度量的环境，是我们观察业务的角度，用来反映业务的一类属性。属性的集合构成维度，维度也可以称为实体对象。例如，在分析交易过程时，可以通过买家、卖家、商品和时间等维度描述交易发生的环境。</p></li><li><p>维度属性：维度所包含的表示维度的列称为维度属性。维度属性是查询约束条件、分组和报表标签生成的基本来源，是数据易用性的关键。</p></li><li><p>度量：在维度建模中，将度量称为事实，将环境描述为维度，维度是用于分析事实所需要的多样环境。度量通常为数值型数据，作为事实逻辑表的事实</p></li><li><p>业务限定：统计的业务范围，筛选出符合业务规则的记录（类似于SQL中<strong>where</strong>后的条件，不包括时间区间）。</p></li><li><p>统计周期：统计的时间范围，例如最近一天，最近30天等（类似于SQL中<strong>where</strong>后的时间条件）。</p></li><li><p>统计粒度：统计分析的对象或视角，定义数据需要汇总的程度，可理解为聚合运算时的分组条件（类似于SQL中的<strong>group by</strong>的对象）。粒度是维度的一个组合，指明您的统计范围。例如，某个指标是某个卖家在某个省份的成交额，则粒度就是卖家、地区这两个维度的组合。如果您需要统计全表的数据，则粒度为全表。在指定粒度时，您需要充分考虑到业务和维度的关系。统计粒度常作为派生指标的修饰词而存在。</p></li></ul><p><img src="https://cdn.jsdelivr.net/gh/onlywsz/onlywsz.github.io/img/202310101519089.jpg" alt="基本概念关系"></p><p><strong>系统内部机制</strong></p><p><img src="https://cdn.jsdelivr.net/gh/onlywsz/onlywsz.github.io/img/202310101519430.jpg" alt="系统内部机制"></p><p><strong>平台架构</strong></p><p><img src="https://cdn.jsdelivr.net/gh/onlywsz/onlywsz.github.io/img/202310101518418.jpg" alt="平台架构"></p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>大数据架构演进</title>
    <link href="/2023/10/09/%E6%95%B0%E6%8D%AE%E6%9E%B6%E6%9E%84%E6%BC%94%E8%BF%9B/"/>
    <url>/2023/10/09/%E6%95%B0%E6%8D%AE%E6%9E%B6%E6%9E%84%E6%BC%94%E8%BF%9B/</url>
    
    <content type="html"><![CDATA[<blockquote><p>导读：随着<strong>数据量的暴增</strong>和<strong>数据实时性要求</strong>越来越高，以及<strong>大数据技术的发展驱动企业不断升级迭代</strong>，数据仓库架构方面也在不断演进，分别经历了以下过程：<strong>早期经典数仓架构 &gt; 离线大数据架构 &gt; Lambda &gt; Kappa &gt; 混合架构。</strong></p></blockquote><p><img src="https://cdn.jsdelivr.net/gh/onlywsz/onlywsz.github.io/img/202310241242801.png"></p><p>主要内容如下：</p><ul><li>大数据架构演进</li><li>早期经典数仓架构</li><li>离线大数据架构</li><li>Lambda架构</li><li>Kappa架构</li><li>Lambda架构与Kappa架构对比</li><li>流批一体架构</li></ul><h1 id="大数据架构演进"><a href="#大数据架构演进" class="headerlink" title="大数据架构演进"></a>大数据架构演进</h1><p><img src="https://cdn.jsdelivr.net/gh/onlywsz/onlywsz.github.io/img/202310241033725.png" alt="大数据架构演进"></p><p>人人都知道罗马不是一天建成的，但没人告诉过你罗马是怎样一天天建成的。你看见罗马时，它就已经是罗马了。对于大部分90后一代，从入行的开始接触的更多的基于Lambda数仓架构；对于95后一代接触的主要以Lambda或混合架构（流批一体）为主。</p><h1 id="早期经典数仓架构"><a href="#早期经典数仓架构" class="headerlink" title="早期经典数仓架构"></a>早期经典数仓架构</h1><p>数据仓库很早之前就有了，也就是说在离线数仓之前(基于大数据架构之前)，有很多传统的数仓技术，例如基于Teradata的数据仓库，只不过是数据仓库技术在大数据背景下发生了很多改变，也就是我们开始抛弃了传统构建数仓的技术，转而选择了更能满足当前时代需求的大数据技术而已，当然大数据技术并没有完整的、彻底的取代传统的技术实现，我们依然可以在很多地方看见它们的身影。</p><p>经典数仓可以将数仓的数仓的不同分层放在不同的数据库中，也可以将不同的分层放在不同的数据库实例上，甚至是可以把不同的分层放在不同的机房。</p><p>大数据技术改变了数仓的存储和计算方式，当然也改变了数仓建模的理念，例如经典数仓数据存储在mysql等关系型数据库上，大数据数仓存储在hadoop平台的hive中（实际上是HDFS中）。这个时期代表的ETL工具：kettle、informatica等.</p><h1 id="离线大数据架构"><a href="#离线大数据架构" class="headerlink" title="离线大数据架构"></a>离线大数据架构</h1><p>背景：互联网诞生之初虽然数据量暴增，单日事实表条数达千万级别，但客户需求场景更多是“t+1”形式，只需对当日、当周、当月数据进行分析，这些诉求仅离线分析就可满足。</p><p>恰逢hadoop生态刚刚兴起之时，数栈技术团队基于数据暴增存储紧张的困境搭载Hadoop生态链，将数据周期性导入HDFS，利用Hadoop平台Hive做数据仓库就可实现对HDFS上的海量数据集进行离线分析。</p><p>这一阶段其实与互联网本质架构没有过多变化，仍是<strong>将数据周期性装载然后分析，只是使用的技术由经典的数仓工具转型到了大数据工具。</strong></p><p><img src="https://cdn.jsdelivr.net/gh/onlywsz/onlywsz.github.io/img/202310241054246.png" alt="离线大数据架构"></p><p>离线大数据数仓优点是架构简单，开发成本与资源成本低，数据容易管理，同时因为没有实时数据，也不会存在离线实时数据 diff 的问题。</p><p>离线大数据数仓最大的问题<strong>首先是数据延迟的问题</strong>，随着业务的复杂性越来越高，数仓复杂度也会不断的提升，需要关联的数据源也越来越多，数据的整体产出时效，就会有各种问题，包括输入数据流断流，数据延迟等在传统数仓常见的问题。</p><p><strong>第二个问题是缺失实时数据</strong>，通常数据的产出时效都是小时或者天级别，有些数据量比较大可能会是周级别甚至月级别产出，无法支撑起业务对数据时效性的诉求。</p><p><strong>第三个问题是表的数量太多</strong>，因为一些复杂的业务场景 ODS 表可能有几百张，产出数据时需要做大量的关联，数仓使用体验变差，同时关联查询也会导致数据产出的时效变差。</p><p><img src="https://cdn.jsdelivr.net/gh/onlywsz/onlywsz.github.io/img/202310241110730.png" alt="离线大数据架构优缺点"></p><h1 id="Lambda架构"><a href="#Lambda架构" class="headerlink" title="Lambda架构"></a>Lambda架构</h1><p>Lambda 架构出现的初衷是为了弥补离线大数据数仓时效性差的问题。Lambda架构的核心思想是<strong>将业务进行拆分，实时性要求高的业务走实时计算方案，实时性要求低的业务走离线计算方案，最后由数据服务层对全部数据进行分析汇总供下游使用。</strong></p><p>整个 Lambda 架构可以分为 3 层，首先图中<strong>最左边的是 Batch Layer 层</strong>，也就是批处理层，在批处理层复用了经典离线数仓的分层架构，在技术栈上也是与经典数仓一致，使用 MR, Hive, Spark 等离线计算框架。</p><p>第二层是<strong>右边的 Speed Layer 加速数据层</strong>，用于产出时效性高的一些数据。Speed Layer 层对数据准确性和完整性会有一些降级。Speed Layer 层采用 Kafka 等消息中间件来进行数据的传输和存储，使用 Storm，Spark Streaming，Flink 进行数据的计算。</p><p>Lambda 架构的<strong>第三层就是 Server 层服务层</strong>，在服务层中会把 Speed 层和 Batch 层的数据进行合并，或者替换输出到数据库中来支持数据应用。</p><p><img src="https://cdn.jsdelivr.net/gh/onlywsz/onlywsz.github.io/img/202310241120337.png" alt="Lambda架构"></p><p>Lambda 层中的 Speed 层让数据的产出时效大大提前了，同时具有 Speed 层和Batch 层让 Lambda 架构兼顾了数据的准确性和时效性。另外Lambda架构中的 Batch 层沿用经典离线数仓的架构，在经典离线数仓迁移到 Lambda 架构时，Lambda 架构是可以兼容经典数仓架构的。</p><p><strong>Lambda 架构的缺点</strong>就是一个需求会有两套代码，一套离线，一套实时，造成了开发成本和运维成本的浪费。第二就是资源的浪费，一份离线资源一份实时资源，两份资源导致整体资源占用比较多。第三个问题就是数据的 diff 问题，因为它是实时和离线两条流，它的数据逻辑本质是不可能完全对齐的，这也是 Lambda 架构最大的一个痛点。</p><p><img src="https://cdn.jsdelivr.net/gh/onlywsz/onlywsz.github.io/img/202310241128733.png" alt="Lambda架构优缺点"></p><h1 id="Kappa架构"><a href="#Kappa架构" class="headerlink" title="Kappa架构"></a>Kappa架构</h1><p>Lambda 架构本身具有 Batch 和 Speed 两条流，Speed 层的数据准确性是不被信任的，主要需要 Batch 层来保证数据的准确性，随着流式计算框架的发展，不重不丢语义的支持，最终演变出了 Kappa 架构。</p><p><strong>Kappa 架构的核心思想就是去掉 Lambda 架构的 Batch 层，实时和离线使用同一套代码，通过一套代码来满足业务对数据的准确性和实时性的要求。</strong></p><p><img src="https://cdn.jsdelivr.net/gh/onlywsz/onlywsz.github.io/img/202310241145570.png" alt="Kappa架构"></p><p>Kappa 架构也不是完美的，比如我们正常的业务会经常遇到一些口径的变更，这些口径的变更会带来数据回溯的问题，因为它是没有离线这条数据流的，数据回溯就需要靠数据重新消费来解决。这种回溯成本非常高，对整个系统的吞吐压力挑战比较大。</p><p>同时，随着业务的复杂度不断增加，它的数据源的复杂度也会增加，随着数据的增加，关联场景比较多，会面临各种复杂关联场景的挑战。关联越来越复杂，开发和维护的成本也会变得非常高。</p><p>第三个就是对于一些新业务，它的数仓基本是从零开始搭建，这个时候搭建一个 Kappa 架构会相对简单，但是我们的数仓建设其实都是有历史包袱的，并非一蹴而就，而是经过一定的演变过来的，这样在改造时就需要对一些存量逻辑做实时的改造，Kappa架构是没有 Batch 这条流的，需要完全替换调离线，这样的改造往往成本是非常高的，同时收益比较小，这也是 Kappa 架构很难大规范铺开的一个很关键原因。</p><p><img src="https://cdn.jsdelivr.net/gh/onlywsz/onlywsz.github.io/img/202310241146376.png" alt="Kappa架构优缺点"></p><h1 id="Lambda架构与Kappa架构对比"><a href="#Lambda架构与Kappa架构对比" class="headerlink" title="Lambda架构与Kappa架构对比"></a>Lambda架构与Kappa架构对比</h1><table><thead><tr><th>对比项</th><th align="left">Lambda架构</th><th>Kappa架构</th></tr></thead><tbody><tr><td>实时性</td><td align="left">实时</td><td>实时</td></tr><tr><td>计算资源</td><td align="left">批和流同时运行，资源消耗大</td><td>只有流处理，仅针对新需求卡法阶段运行两个作业，资源开销小</td></tr><tr><td>重新计算时吞吐</td><td align="left">批式全量处理、吞吐量高</td><td>流式全量处理、吞吐较批处理低</td></tr><tr><td>开发、测试难度</td><td align="left">每个需求都需要两套不同代码、开发、测试、上线难度较大</td><td>只需要一套代码、开发、测试、上线难度相对较小</td></tr><tr><td>运维成本</td><td align="left">维护两套系统（引擎）、运维成本大</td><td>只需要维护一套系统、运维成本小</td></tr><tr><td>分布式计算技术</td><td align="left">SparkStreaming&#x2F;Storm</td><td>Flink</td></tr><tr><td>分布式存储技术</td><td align="left">HDFS系列为主</td><td>HDFS、对象存储</td></tr></tbody></table><p>​                           </p><h1 id="流批一体架构"><a href="#流批一体架构" class="headerlink" title="流批一体架构"></a>流批一体架构</h1><p>背景：在2020年发布Flink-1.12.0之后 <a href="https://nightlies.apache.org/flink/flink-docs-release-1.14/zh/docs/flinkdev/ide_setup/">Flink官网 </a>。FlinkX是一款基于Flink的流批统一的数据同步以及SQL计算工具。既可以采集静态的数据，比如MySQL，HDFS中的业务数据，也可以采集实时变化的数据，比如MySQL、 Binlog、Kafka等。在FlinkX1.12中，也会将FlinkStreamSql融合其中，使得FlinkX1.12既能通过同步任务采集静态、动态的数据，又能通过SQL任务对采集后的数据根据业务时效性进行流批处理。</p><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs markdown">流批一体包括四个方面：<br><br><span class="hljs-bullet">1.</span> 数据集成流批一体:离线与实时是否使用统一数据采集方式；如统一通过 CDC 或者 OGG 将数据实时捕获推送到 kafka，批与流在从 kafka 中消费数据，载入明细层。<br><br><span class="hljs-bullet">2.</span> 数据存储流批一体：离线与实时数据是否统一分层、统一存储；兼容数据的一致性和实时性。<br><br><span class="hljs-bullet">3.</span> 处理逻辑流批一体：流与批处理是否使用统一SQL语法或者ETL组件，再通过底层分别适配流与批计算引擎，保证数据口径的一致性。<br><br><span class="hljs-bullet">4.</span> 计算引擎流批一体：流与批使用同一套计算引擎，从根本上避免同一个处理逻辑流批两套代码问题。<br><br></code></pre></td></tr></table></figure><p>FlinkX Sql能支持流批计算的能力来源于Flink内核在1.12版本中对元数据的统一管理以及在DataStream API上支持批执行模式，这样增强了作业的可复用性和可维护性，使得FlinkX 作业可以在流和批两种执行模式之间自由进行切换并只需要维护一套代码，无需重新写任何代码。而且，相比于开源的Flink，FlinkX 1.12 不仅提供了更多的Source以及Sink来支持对各类数据源的实时以及离线计算还实现了脏数据管理插件，让客户在ETL阶段针对错误不合规的数据能够由感知以及容错处理能力。</p><p><img src="https://cdn.jsdelivr.net/gh/onlywsz/onlywsz.github.io/img/202310241706322.png" alt="流批一体架构"></p><p><strong>流批一体可以看作是对Lambda架构的简化，也是实时处理和批处理融合的产物，以应对实时数据和历史数据双需求的场景。</strong></p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>数据架构经历了如下演变：</p><ul><li>经典数仓架构 –&gt; 传统大数据架构（解决数据量的问题，但业务延迟高）</li><li>传统大数据架构 –&gt; Lambda架构（解决数据实时性低的问题，用实时层保证低延迟，用离线层保证数据最终一致性，但架构复杂、计算逻辑口径难以一致）</li><li>Lambda架构 –&gt; Kappa架构（解决架构冗余问题和计算逻辑口径不一致的问题，但消息队列数据生命周期短）</li></ul><p>最终，在Lambda架构的基础上采用了流批一体实现方案，使得系统复杂度降低，计算逻辑口径达成一致。</p><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><p>阿里云：<a href="https://developer.aliyun.com/article/1293821">阿里云社区</a></p><p>DataFunTalk：<a href="https://zhuanlan.zhihu.com/p/597355365">知乎</a></p><p>腾讯云社区：<a href="https://cloud.tencent.com/developer/article/1939580">腾讯云</a></p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>埋点体系</title>
    <link href="/2023/09/11/%E5%9F%8B%E7%82%B9%E4%BD%93%E7%B3%BB%20(%E6%A6%82%E5%BF%B5%E7%AF%87)/"/>
    <url>/2023/09/11/%E5%9F%8B%E7%82%B9%E4%BD%93%E7%B3%BB%20(%E6%A6%82%E5%BF%B5%E7%AF%87)/</url>
    
    <content type="html"><![CDATA[<blockquote><p>概念篇：了解埋点是啥、有啥用、有哪些方案、到底采的什么数据、埋点方式</p></blockquote><h1 id="什么是埋点"><a href="#什么是埋点" class="headerlink" title="什么是埋点"></a>什么是埋点</h1><p><img src="https://cdn.jsdelivr.net/gh/onlywsz/onlywsz.github.io/img/202310101629067.png"></p><center>用户做了某个操作之后，向服务器/BI发送了一条或多条日志，这个日志就是埋点。</center><h1 id="埋点的作用"><a href="#埋点的作用" class="headerlink" title="埋点的作用"></a>埋点的作用</h1><p>* </p><p><img src="https://cdn.jsdelivr.net/gh/onlywsz/onlywsz.github.io/img/202310101629241.png" alt="maidianzuoyong"></p><h1 id="埋点方案"><a href="#埋点方案" class="headerlink" title="埋点方案"></a>埋点方案</h1><p><img src="https://cdn.jsdelivr.net/gh/onlywsz/onlywsz.github.io/img/202310102347339.png"></p><h1 id="采集的数据源"><a href="#采集的数据源" class="headerlink" title="采集的数据源"></a>采集的数据源</h1><h1 id="埋点方式"><a href="#埋点方式" class="headerlink" title="埋点方式"></a>埋点方式</h1><h1 id="触发时机"><a href="#触发时机" class="headerlink" title="触发时机"></a>触发时机</h1><h1 id="上报策略"><a href="#上报策略" class="headerlink" title="上报策略"></a>上报策略</h1><h1 id="埋点设计"><a href="#埋点设计" class="headerlink" title="埋点设计"></a>埋点设计</h1><h1 id="事件模型"><a href="#事件模型" class="headerlink" title="事件模型"></a>事件模型</h1><h1 id="物理模型"><a href="#物理模型" class="headerlink" title="物理模型"></a>物理模型</h1><h1 id="传参模式"><a href="#传参模式" class="headerlink" title="传参模式"></a>传参模式</h1><h1 id="用户标识"><a href="#用户标识" class="headerlink" title="用户标识"></a>用户标识</h1>]]></content>
    
    
    <categories>
      
      <category>埋点</category>
      
    </categories>
    
    
    <tags>
      
      <tag>埋点</tag>
      
      <tag>数据采集</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>埋点体系总览</title>
    <link href="/2023/09/11/%E5%9F%8B%E7%82%B9%E4%BD%93%E7%B3%BB/"/>
    <url>/2023/09/11/%E5%9F%8B%E7%82%B9%E4%BD%93%E7%B3%BB/</url>
    
    <content type="html"><![CDATA[<blockquote><p>做数产的第四个年头了，早就想针对埋点知识体系做一个全面的梳理，其实很难用一点点篇幅就把埋点这个事情讲清楚，处在不同的角色对埋点认知、要求参差不齐；对业务侧产品来说按照规范会埋点、对数分来说理解表结构能提取数据、对数开来说能针对事件维度建模、对数据产品&#x2F;专家来说，就要全面的、系统的考虑埋点的<u>规范、设计、传输、存储、计算、落盘、应用、治理</u>等等。</p></blockquote><p>声明：通过以下七篇让大家对埋点知识体系大彻大悟、醍醐灌地，本人有这个自信！全是干货没有废话！！</p><h1 id="概念篇"><a href="#概念篇" class="headerlink" title="概念篇"></a>概念篇</h1><h1 id="规范篇"><a href="#规范篇" class="headerlink" title="规范篇"></a>规范篇</h1><h1 id="设计篇"><a href="#设计篇" class="headerlink" title="设计篇"></a>设计篇</h1><h1 id="技术篇"><a href="#技术篇" class="headerlink" title="技术篇"></a>技术篇</h1><h1 id="应用篇"><a href="#应用篇" class="headerlink" title="应用篇"></a>应用篇</h1><h1 id="治理篇"><a href="#治理篇" class="headerlink" title="治理篇"></a>治理篇</h1><h1 id="思考篇"><a href="#思考篇" class="headerlink" title="思考篇"></a>思考篇</h1>]]></content>
    
    
    <categories>
      
      <category>埋点</category>
      
    </categories>
    
    
    <tags>
      
      <tag>埋点</tag>
      
      <tag>数据采集</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Hello World</title>
    <link href="/2023/09/10/hello-world/"/>
    <url>/2023/09/10/hello-world/</url>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo new <span class="hljs-string">&quot;My New Post&quot;</span><br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo server<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo generate<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo deploy<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
    
    
    
  </entry>
  
  
  
  
</search>
